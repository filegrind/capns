{
  "urn": {
    "tags": {
      "op": "generate_image_embeddings",
      "model_type": "candle",
      "in": "media:png;binary",
      "out": "media:embedding-vector;textable;keyed"
    }
  },
  "command": "generate_image_embeddings",
  "title": "Generate Image Embeddings (Candle)",
  "cap_description": "Generate image embeddings using CLIP models with Candle ML framework",
  "metadata": {},
  "media_specs": {
    "media:embedding-vector;textable;keyed": {
      "media_type": "application/json",
      "profile_uri": "https://capns.org/schema/image-embeddings",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "required": [
          "model_name",
          "embedding_dim",
          "image_path",
          "embedding"
        ],
        "properties": {
          "model_name": {
            "type": "string",
            "minLength": 1,
            "description": "Name of the CLIP model used"
          },
          "embedding_dim": {
            "type": "integer",
            "minimum": 1,
            "description": "Dimensionality of the embedding vector"
          },
          "image_path": {
            "type": "string",
            "description": "Path to the embedded image"
          },
          "embedding": {
            "type": "array",
            "items": {
              "type": "number"
            },
            "description": "The image embedding vector"
          },
          "generation_time_ms": {
            "type": "integer",
            "minimum": 0,
            "description": "Embedding generation time in milliseconds"
          }
        }
      }
    },
    "media:embedding-vector-batch;textable;keyed;sequence": {
      "media_type": "application/json",
      "profile_uri": "https://capns.org/schema/image-embeddings-batch-output",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "required": [
          "model_name",
          "embedding_dim",
          "total_images",
          "results"
        ],
        "properties": {
          "model_name": {
            "type": "string",
            "minLength": 1,
            "description": "Name of the CLIP model used"
          },
          "embedding_dim": {
            "type": "integer",
            "minimum": 1,
            "description": "Dimensionality of the embedding vectors"
          },
          "total_images": {
            "type": "integer",
            "minimum": 0,
            "description": "Total number of images processed"
          },
          "results": {
            "type": "array",
            "description": "Array of image embedding results",
            "items": {
              "type": "object",
              "additionalProperties": false,
              "required": [
                "image_path",
                "embedding"
              ],
              "properties": {
                "image_path": {
                  "type": "string",
                  "description": "Path to the image"
                },
                "embedding": {
                  "type": "array",
                  "items": {
                    "type": "number"
                  },
                  "description": "The embedding vector"
                }
              }
            }
          }
        }
      }
    }
  },
  "args": [
    {
      "media_urn": "media:image-path;textable;scalar",
      "required": true,
      "sources": [
        {
          "cli_flag": "--image"
        },
        {
          "position": 0
        }
      ],
      "arg_description": "Path to the image file to embed",
      "validation": {
        "pattern": "^[^\\0]+$",
        "min_length": 1
      }
    },
    {
      "media_urn": "media:hf-model-name;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--model"
        }
      ],
      "arg_description": "CLIP model name from HuggingFace",
      "validation": {
        "min_length": 1,
        "max_length": 256
      },
      "default_value": "openai/clip-vit-base-patch32"
    },
    {
      "media_urn": "media:output-path;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--output"
        }
      ],
      "arg_description": "Output JSON file path",
      "validation": {
        "pattern": "^[^\\0]+$"
      }
    }
  ],
  "output": {
    "media_urn": "media:embedding-vector;textable;keyed",
    "output_description": "Image embedding vector with model metadata"
  }
}