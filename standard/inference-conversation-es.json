{
  "urn": {
    "tags": {
      "action": "conversation",
      "language": "es",
      "type": "constrained"
    }
  },
  "version": "1.0.0",
  "command": "llm_inference",
  "cap_description": "Conversación natural y respuestas de chat en español",
  "metadata": {},
  "accepts_stdin": true,
  "arguments": {
    "required": [
      {
        "name": "prompt",
        "arg_type": "string",
        "arg_description": "Entrada conversacional del usuario",
        "cli_flag": "--prompt",
        "position": 0,
        "validation": {
          "min_length": 1,
          "max_length": 32768
        }
      }
    ],
    "optional": [
      {
        "name": "context",
        "arg_type": "string",
        "arg_description": "Contexto e historial de conversación",
        "cli_flag": "--context",
        "validation": {
          "max_length": 65536
        }
      },
      {
        "name": "max_tokens",
        "arg_type": "number",
        "arg_description": "Máximo de tokens a generar",
        "cli_flag": "--max-tokens",
        "default_value": 2000,
        "validation": {
          "min": 1,
          "max": 8192
        }
      },
      {
        "name": "temperature",
        "arg_type": "number",
        "arg_description": "Temperatura de muestreo para creatividad vs consistencia",
        "cli_flag": "--temperature",
        "default_value": 0.7,
        "validation": {
          "min": 0,
          "max": 2
        }
      },
      {
        "name": "system_prompt",
        "arg_type": "string",
        "arg_description": "Instrucciones del sistema para comportamiento conversacional",
        "cli_flag": "--system-prompt",
        "validation": {
          "max_length": 8192
        }
      }
    ]
  },
  "output": {
    "output_type": "object",
    "output_description": "Respuesta conversacional generada con información de contexto",
    "content_type": "application/json"
  }
}