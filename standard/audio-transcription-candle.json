{
  "urn": {
    "tags": {
      "op": "transcribe",
      "model_type": "candle",
      "in": "media:wav;audio;binary;",
      "out": "media:transcription-output;textable;keyed"
    }
  },
  "command": "transcribe",
  "title": "Transcribe Audio (Candle)",
  "cap_description": "Transcribe audio files to text using Whisper models with Candle ML framework",
  "metadata": {},
  "media_specs": {
    "media:transcription-output;textable;keyed": {
      "media_type": "application/json",
      "profile_uri": "https://capns.org/schema/transcription-output",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "required": [
          "model_name",
          "audio_path",
          "language",
          "text"
        ],
        "properties": {
          "model_name": {
            "type": "string",
            "minLength": 1,
            "description": "Name of the Whisper model used"
          },
          "audio_path": {
            "type": "string",
            "description": "Path to the transcribed audio file"
          },
          "language": {
            "type": "string",
            "description": "Language of the transcription"
          },
          "text": {
            "type": "string",
            "description": "Full transcribed text"
          },
          "segments": {
            "type": "array",
            "description": "Timestamped segments (if timestamps enabled)",
            "items": {
              "type": "object",
              "additionalProperties": false,
              "required": [
                "segment_index",
                "start_time",
                "end_time",
                "text"
              ],
              "properties": {
                "segment_index": {
                  "type": "integer",
                  "minimum": 0,
                  "description": "Index of this segment"
                },
                "start_time": {
                  "type": "number",
                  "minimum": 0,
                  "description": "Start time in seconds"
                },
                "end_time": {
                  "type": "number",
                  "minimum": 0,
                  "description": "End time in seconds"
                },
                "text": {
                  "type": "string",
                  "description": "Text content of this segment"
                }
              }
            }
          },
          "duration_seconds": {
            "type": "number",
            "minimum": 0,
            "description": "Total audio duration in seconds"
          },
          "transcription_time_ms": {
            "type": "integer",
            "minimum": 0,
            "description": "Transcription time in milliseconds"
          }
        }
      }
    }
  },
  "args": [
    {
      "media_urn": "media:audio-path;textable;scalar",
      "required": true,
      "sources": [
        {
          "cli_flag": "--audio"
        },
        {
          "position": 0
        }
      ],
      "arg_description": "Path to the audio file (WAV format)",
      "validation": {
        "pattern": "^[^\\0]+$",
        "min_length": 1
      }
    },
    {
      "media_urn": "media:language-code;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--language"
        }
      ],
      "arg_description": "Language code for transcription",
      "validation": {
        "pattern": "^[a-z]{2}$"
      },
      "default_value": "en"
    },
    {
      "media_urn": "media:timestamps-flag;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--timestamps"
        }
      ],
      "arg_description": "Include timestamps in output",
      "default_value": false
    },
    {
      "media_urn": "media:hf-model-name;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--model"
        }
      ],
      "arg_description": "Whisper model name from HuggingFace",
      "validation": {
        "min_length": 1,
        "max_length": 256
      },
      "default_value": "openai/whisper-base"
    },
    {
      "media_urn": "media:output-path;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--output"
        }
      ],
      "arg_description": "Output JSON file path",
      "validation": {
        "pattern": "^[^\\0]+$"
      }
    }
  ],
  "output": {
    "media_urn": "media:transcription-output;textable;keyed",
    "output_description": "Transcribed text with optional timestamps and metadata"
  }
}