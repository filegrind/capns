{
  "urn": {
    "tags": {
      "op": "load",
      "type": "model",
      "in": "std:void.v1",
      "out": "capns:load-output.v1"
    }
  },
  "command": "load",
  "title": "Load Model",
  "cap_description": "Load a model into memory for inference operations",
  "metadata": {},
  "media_specs": {
    "capns:load-output.v1": {
      "media_type": "application/json",
      "profile_uri": "https://capns.org/schema/load-output",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether the model was loaded successfully"
          },
          "model_name": {
            "type": "string",
            "minLength": 1,
            "description": "Name of the loaded model"
          },
          "model_handle": {
            "type": "string",
            "description": "Handle/ID for the loaded model instance"
          },
          "device": {
            "type": "string",
            "enum": [
              "cpu",
              "cuda",
              "mps"
            ],
            "description": "Device the model was loaded on"
          },
          "precision": {
            "type": "string",
            "enum": [
              "float32",
              "float16",
              "int8",
              "int4"
            ],
            "description": "Model precision"
          },
          "memory_usage_mb": {
            "type": "integer",
            "minimum": 0,
            "description": "Memory usage in megabytes"
          },
          "load_time_ms": {
            "type": "integer",
            "minimum": 0,
            "description": "Load time in milliseconds"
          },
          "model_config": {
            "type": "object",
            "additionalProperties": true,
            "description": "Model configuration parameters"
          }
        },
        "required": [
          "success",
          "model_name"
        ]
      }
    }
  },
  "accepts_stdin": false,
  "arguments": {
    "required": [
      {
        "name": "model",
        "media_spec": "std:str.v1",
        "arg_description": "Model identifier or path to load",
        "cli_flag": "--model",
        "position": 0,
        "validation": {
          "pattern": "^[^\\0]+$",
          "min_length": 1
        }
      }
    ],
    "optional": [
      {
        "name": "device",
        "media_spec": "std:str.v1",
        "arg_description": "Device to load model on",
        "cli_flag": "--device",
        "default_value": "cpu",
        "validation": {
          "allowed_values": [
            "cpu",
            "cuda",
            "mps",
            "auto"
          ]
        }
      },
      {
        "name": "precision",
        "media_spec": "std:str.v1",
        "arg_description": "Model precision/quantization level",
        "cli_flag": "--precision",
        "default_value": "float32",
        "validation": {
          "allowed_values": [
            "float32",
            "float16",
            "int8",
            "int4"
          ]
        }
      }
    ]
  },
  "output": {
    "media_spec": "capns:load-output.v1",
    "output_description": "Load result with model handle and configuration"
  }
}