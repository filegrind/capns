{
  "urn": {
    "tags": {
      "op": "load-model",
      "in": "media:model-id;textable;scalar",
      "out": "media:load-output;textable;keyed"
    }
  },
  "command": "load",
  "title": "Load Model",
  "cap_description": "Load a model into memory for inference operations",
  "metadata": {},
  "media_specs": {
    "media:load-output;textable;keyed": {
      "media_type": "application/json",
      "profile_uri": "https://capns.org/schema/load-output",
      "schema": {
        "type": "object",
        "additionalProperties": false,
        "properties": {
          "success": {
            "type": "boolean",
            "description": "Whether the model was loaded successfully"
          },
          "model_name": {
            "type": "string",
            "minLength": 1,
            "description": "Name of the loaded model"
          },
          "model_handle": {
            "type": "string",
            "description": "Handle/ID for the loaded model instance"
          },
          "device": {
            "type": "string",
            "enum": [
              "cpu",
              "cuda",
              "mps"
            ],
            "description": "Device the model was loaded on"
          },
          "precision": {
            "type": "string",
            "enum": [
              "float32",
              "float16",
              "int8",
              "int4"
            ],
            "description": "Model precision"
          },
          "memory_usage_mb": {
            "type": "integer",
            "minimum": 0,
            "description": "Memory usage in megabytes"
          },
          "load_time_ms": {
            "type": "integer",
            "minimum": 0,
            "description": "Load time in milliseconds"
          },
          "model_config": {
            "type": "object",
            "additionalProperties": true,
            "description": "Model configuration parameters"
          }
        },
        "required": [
          "success",
          "model_name"
        ]
      }
    }
  },
  "args": [
    {
      "media_urn": "media:model-id;textable;scalar",
      "required": true,
      "sources": [
        {
          "cli_flag": "--model"
        },
        {
          "position": 0
        }
      ],
      "arg_description": "Model identifier or path to load",
      "validation": {
        "pattern": "^[^\\0]+$",
        "min_length": 1
      }
    },
    {
      "media_urn": "media:device;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--device"
        }
      ],
      "arg_description": "Device to load model on",
      "validation": {
        "allowed_values": [
          "cpu",
          "cuda",
          "mps",
          "auto"
        ]
      },
      "default_value": "cpu"
    },
    {
      "media_urn": "media:precision;textable;scalar",
      "required": false,
      "sources": [
        {
          "cli_flag": "--precision"
        }
      ],
      "arg_description": "Model precision/quantization level",
      "validation": {
        "allowed_values": [
          "float32",
          "float16",
          "int8",
          "int4"
        ]
      },
      "default_value": "float32"
    }
  ],
  "output": {
    "media_urn": "media:load-output;textable;keyed",
    "output_description": "Load result with model handle and configuration"
  }
}